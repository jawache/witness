# Witness Development Log

This log chronicles the development journey of Witness, an Obsidian plugin that implements the Model Context Protocol (MCP) to enable AI-assisted vault management.

---

## 2026-01-30 - Phase 1: MCP Server Implementation

**Objective**: Create an Obsidian plugin that acts as an MCP server running inside Obsidian, enabling Claude Desktop to interact with the vault.

### What We Built

Implemented a complete MCP server with 6 core tools:

1. **read_file** - Read any file from the vault
2. **write_file** - Create or modify files
3. **list_files** - Browse directory contents
4. **edit_file** - Find and replace text (surgical edits)
5. **search** - Full-text search across all markdown files
6. **execute_command** - Execute any Obsidian command by ID

### The Journey

**Morning: Architecture Decision**

Started with a critical architectural choice: Should the plugin BE the MCP server (Approach A) or should it be an external server connecting via REST API (Approach B)?

Decision: **Approach A** - Plugin runs the MCP server directly inside Obsidian. This means:
- Zero dependencies on other plugins
- Direct access to Obsidian's Vault API
- HTTP server running in Electron process
- More complex but more powerful

**Early Development: Initial Implementation**

First attempt was manual JSON-RPC message handling. Messy and error-prone. Quickly pivoted to using the official `@modelcontextprotocol/sdk` package for proper protocol compliance.

Initial tools: read_file, write_file, list_files working with manual testing via curl.

**The Great Session Management Mystery**

Hit a major blocker: "Server already initialized" error on every connection attempt from Claude Desktop. Spent considerable time investigating:

1. **Red Herring #1**: Node version issues
   - mcp-remote showed "File is not defined" errors
   - Tried forcing Node v24 via PATH environment
   - Turned out to be irrelevant - still works with Node v18

2. **The Real Problem**: Session Management
   - Was creating a new transport for EVERY HTTP request
   - Should create ONE transport per SESSION
   - Maintain a `Map<sessionId, transport>`
   - Only call `mcpServer.connect(transport)` once per session
   - Reuse transport for all subsequent requests in that session

**Breakthrough**: Found the pattern in SDK examples at `node_modules/@modelcontextprotocol/sdk/dist/esm/examples/server/simpleStreamableHttp.js`. The key insight: StreamableHTTP is stateful. Sessions span multiple HTTP requests.

**Second Major Issue**: SSE Stream 404 Errors

Tools were listing successfully, but then Claude Desktop couldn't establish the SSE (Server-Sent Events) stream for receiving notifications.

Problem: Only handling POST requests to `/mcp`, not GET requests.

Solution: StreamableHTTP uses dual endpoints:
- POST for sending JSON-RPC messages
- GET for SSE streams (receiving)

Also had to handle GET requests differently - no body to parse.

**Late Afternoon: Completing the Tool Set**

With the connection working, implemented the remaining three tools:

1. **edit_file**: Find/replace with proper regex escaping for literal matching
2. **search**: Full-text search with optional case sensitivity and path filtering
3. **execute_command**: Direct access to Obsidian's command system

All tools use Zod schemas for parameter validation, letting the SDK auto-generate JSON Schema.

### Technical Achievements

- **Proper Session Management**: Map-based transport tracking
- **SSE Support**: Bidirectional communication working
- **Type Safety**: Zod validation for all parameters
- **Error Handling**: Clear error messages with helpful suggestions
- **Zero External Dependencies**: No REST API plugins needed

### Documentation Created

- **README.md**: User-facing installation and usage guide
- **CLAUDE.md**: Technical implementation details for AI assistants
- **PHASE1-COMPLETE.md**: Comprehensive tool reference with examples
- **test-tools.sh**: Testing verification script
- **DEVLOG**: This file

### Key Learnings

1. **StreamableHTTP is stateful**: Don't create new transports per request
2. **Dual endpoints matter**: Handle both POST and GET for full functionality
3. **Read the SDK examples**: The answers are often in the source code
4. **Test methodically**: Health endpoint + logs + screenshots = debugging trinity
5. **Document as you go**: Future you will thank present you

### Statistics

- **4 commits** in main branch
- **452 lines** of TypeScript
- **6 tools** implemented
- **100%** Phase 1 objectives met

### Next Steps

Phase 2: Remote Access
- Cloudflare Tunnel integration
- WhatsApp/Telegram bot connection
- Mobile support
- Multi-user authentication
- Security hardening

### Reflections

The session management bug was frustrating but educational. It reinforced the importance of:
- Reading official examples thoroughly
- Not assuming the first error message is the real problem
- Systematic debugging rather than guessing
- Writing documentation that captures the "why" not just the "what"

Phase 1 is complete and working beautifully. The foundation is solid for Phase 2 expansion.

---

## 2026-01-31 - Integration Test Suite

**Objective**: Build automated testing infrastructure to verify MCP tools work correctly end-to-end.

### What We Built

A complete integration test suite using Vitest that tests all MCP tools against a running Obsidian instance.

**Test Infrastructure:**
- `test/vault/` - Minimal, stable test vault with known fixed content
- `test/integration/mcp-client.ts` - MCP protocol client for testing
- `test/integration/mcp.test.ts` - 17 integration tests covering all tools
- `test/vitest.config.ts` - Test configuration

**Vault Reorganization:**
- Renamed `test-vault/` → `demo-vault/` for manual testing and development
- Created `test/vault/` for automated tests (port 3001)
- Clear separation: demo vault can change freely, test vault stays stable

**NPM Scripts:**
- `npm test` - Run integration tests
- `npm run test:watch` - Watch mode
- `npm run test:start-obsidian` - Launch Obsidian with test vault
- `npm run test:install-plugin` - Build and install plugin

### The Journey

**Design Decision: Integration vs Unit Tests**

Considered two approaches:
1. Mock-based unit tests - Fast but doesn't test real integration
2. Integration tests against running Obsidian - Slower but tests actual behavior

Chose integration tests because:
- Most plugin logic is tightly coupled to Obsidian's API
- Mocking the vault would be complex and fragile
- We need to verify files are actually created/modified
- MCP protocol nuances are hard to unit test

**Test Verification Strategy**

Made sure tests actually verify results, not just check for errors:
- `write_file`: Writes content, then reads it back to verify
- `edit_file`: Performs edit, then reads file to confirm change
- `read_file`: Checks returned content matches known file content
- `search`: Verifies correct files appear in results

**Initial Test Failures**

First run: 14/17 tests passed. The 3 failures were because MCP returns errors via `isError: true` flag rather than throwing exceptions. Updated tests to check `result.isError` instead of `expect(...).rejects.toThrow()`.

Second run: 17/17 tests pass.

### Technical Achievements

- **True End-to-End Testing**: Tests run against real Obsidian instance
- **All Tools Covered**: 17 tests for 8 MCP tools
- **Error Case Coverage**: Tests both success and error paths
- **Result Verification**: Tests read back data to verify operations worked
- **Clean Separation**: Test vault isolated from demo/development vault

### Test Coverage Summary

| Tool | Tests | Verification |
|------|-------|--------------|
| read_file | 2 | Content matches known file |
| write_file | 2 | Read back verifies content |
| edit_file | 2 | Read back verifies changes |
| list_files | 2 | Expected files present |
| search | 2 | Correct files in results |
| find_files | 2 | Pattern matching works |
| get_orientation | 1 | Returns orientation doc |
| execute_command | 2 | Success/error handling |

### Key Learnings

1. **MCP error handling**: Errors return `isError: true`, not exceptions
2. **TypeScript config**: Need to exclude test directory from main build
3. **Vitest config**: `sequence.concurrent: false` for sequential tests
4. **Port separation**: Test vault uses 3001 to avoid conflicts with demo

### Statistics

- **17 tests** all passing
- **166ms** test duration
- **2 vaults** (demo + test)
- **4 npm scripts** for testing workflow

### Next Steps

- Consider adding GitHub Actions CI
- Add more edge case tests as bugs are found
- Potential: Screenshot tests for UI verification

---

## 2026-01-31 - File-Based MCP Logging

**Objective**: Implement file-based logging so logs are accessible without Obsidian's Developer Console.

### What We Built

A logging system that writes MCP server logs to files in the plugin directory.

**MCPLogger Class:**

- Writes to both console AND file simultaneously
- Buffered writes (flushes every 1 second or 50 entries)
- Date-based log files: `mcp-YYYY-MM-DD.log`
- Log levels: INFO, ERROR, DEBUG, MCP
- ISO timestamps for all entries
- Graceful shutdown flushes remaining logs

**Log Location:**

```text
.obsidian/plugins/witness/logs/mcp-2026-01-31.log
```

**Log Format:**

```text
[2026-01-31T17:49:56.003Z] [INFO] Witness plugin loaded
[2026-01-31T17:50:07.214Z] [MCP] POST /mcp
[2026-01-31T17:50:07.242Z] [MCP] read_file called with path: "test.md"
```

### Benefits

1. **Debugging**: Claude Code can read logs directly to help debug issues
2. **Bug Reports**: Users can easily share logs when reporting problems
3. **No Console Required**: No need to open Developer Console to see what's happening
4. **History**: Date-based files provide historical record

### Testing

Added 2 new integration tests (now 19 total):

1. **should write logs to file** - Verifies log file exists and contains expected entries
2. **should log error cases** - Verifies failed operations are logged

### Implementation Details

Replaced all `console.log` and `console.error` calls with `this.logger.*` calls:

- `this.logger.info()` - General information
- `this.logger.error()` - Error conditions
- `this.logger.debug()` - Debug info
- `this.logger.mcp()` - MCP protocol-level logging

The logger buffers writes to avoid I/O overhead on every log call.

### Statistics

- **2 new tests** added
- **19 tests** total, all passing
- **~150 lines** of logging code
- **1 new class** (MCPLogger)

### Next Steps

- Implement `move_file` tool for moving/renaming files
- Consider log rotation for large vaults

---

## 2026-01-31 - Move/Rename File Tool

**Objective**: Implement `move_file` MCP tool to move or rename files within the vault.

### What We Built

A new `move_file` MCP tool that enables AI assistants to move or rename files within the vault using Obsidian's native `vault.rename()` API.

**Tool Implementation:**

- Takes `from` (source path) and `to` (destination path) parameters
- Uses Obsidian's `vault.rename()` for proper file system handling
- Automatically creates parent directories if needed
- Error handling for: source not found, destination already exists
- Marked as destructive (destructiveHint: true)
- Full logging integration

**Test Coverage:**

Added 4 new integration tests (23 total):
1. Should move/rename a file
2. Should move file to subfolder
3. Should return error for non-existent source
4. Should return error if destination exists

### Technical Details

```typescript
this.mcpServer.tool(
  'move_file',
  'Move or rename a file within the vault',
  {
    from: z.string().describe('Current path of the file'),
    to: z.string().describe('New path for the file'),
  },
  { destructiveHint: true },
  async ({ from, to }) => {
    const file = this.app.vault.getAbstractFileByPath(from);
    if (!file) throw new Error(`Source file not found: ${from}`);

    const existing = this.app.vault.getAbstractFileByPath(to);
    if (existing) throw new Error(`Destination already exists: ${to}`);

    // Create parent directories if needed
    const destDir = to.substring(0, to.lastIndexOf('/'));
    if (destDir) {
      const parentFolder = this.app.vault.getAbstractFileByPath(destDir);
      if (!parentFolder) {
        await this.app.vault.createFolder(destDir);
      }
    }

    await this.app.vault.rename(file, to);
    return { content: [{ type: 'text', text: `Moved ${from} to ${to}` }] };
  }
);
```

### Key Features

- **Preserves Metadata**: Unlike delete + create, rename preserves file creation date and other metadata
- **Parent Directory Creation**: Automatically creates destination directories if they don't exist
- **Conflict Prevention**: Fails safely if destination already exists
- **Full Logging**: Integrated with MCPLogger for debugging

### Statistics

- **4 new tests** added
- **23 tests** total, all passing
- **~50 lines** of new tool code
- **9 MCP tools** now available

### Next Steps

- Remote Access via Cloudflare Tunnel (Phase 2)

---

## 2026-01-31 - Cloudflare Quick Tunnel Integration

**Objective**: Enable remote access to the Witness MCP server via Cloudflare's Quick Tunnel feature.

### What We Built

A complete tunneling solution that exposes the local MCP server to the internet, allowing Claude to connect from anywhere.

**Key Features:**

- **Zero-Config Tunneling**: Toggle "Enable Quick Tunnel" in settings and get a public URL
- **Auto-Install**: cloudflared binary automatically downloads on first use to `~/.witness/bin/`
- **Settings UI**: Display current URL with copy button, regenerate button, status indicator
- **Notifications**: Toast notification when tunnel connects with URL

**Architecture:**

```text
Claude (anywhere)
    ↓ HTTPS
Cloudflare Edge (random-words.trycloudflare.com)
    ↓ Tunnel
cloudflared binary (running on user's machine)
    ↓ HTTP
Witness Plugin (localhost:3000)
    ↓
Obsidian Vault
```

### The Journey

**Challenge: Binary Path Resolution**

Initial attempt failed with:

```text
spawn /Applications/Obsidian.app/Contents/Resources/electron.asar/bin/cloudflared ENOENT
```

The cloudflared npm package couldn't find its binary inside Obsidian's Electron environment. The package looks for the binary relative to its module location, but bundling breaks this.

**Solution: Custom Binary Management**

1. Install cloudflared to a known, stable location: `~/.witness/bin/cloudflared`
2. Use the package's `use()` function to point to our binary location
3. Handle first-run installation automatically

```typescript
private getCloudflaredBinPath(): string {
  const binDir = path.join(os.homedir(), '.witness', 'bin');
  return path.join(binDir, 'cloudflared');
}

await installCloudflared(binPath);  // Install to our location
useCloudflared(binPath);            // Tell package where to find it
```

**esbuild Configuration**

Also needed to update `esbuild.config.mjs` to handle `node:` prefixed module specifiers:

```javascript
const nodeBuiltins = builtins.flatMap(m => [m, `node:${m}`]);
// Add platform: "node" for proper Node.js target
```

### Implementation Details

**Settings Interface:**

```typescript
interface WitnessSettings {
  // ... existing
  enableTunnel: boolean;
  tunnelUrl: string | null;
}
```

**Tunnel Lifecycle:**

1. On plugin load: Start tunnel if enabled
2. On plugin unload: Stop tunnel gracefully
3. Regenerate: Stop, wait, restart

**Event Handling:**

```typescript
const tunnel = Tunnel.quick(localUrl);
tunnel.once('url', async (url) => {
  this.settings.tunnelUrl = url;
  await this.saveSettings();
  new Notice(`Tunnel connected: ${url}/mcp`);
});
tunnel.once('connected', (conn) => {
  this.logger.info(`Connected to ${conn.location}`);
});
tunnel.on('exit', (code) => {
  this.tunnelProcess = null;
  this.tunnelStatus = 'disconnected';
});
```

### Testing

Verified end-to-end:

```bash
# Health check through tunnel
curl https://bought-funky-charges-reservation.trycloudflare.com/health
# {"status":"ok","plugin":"witness"}

# MCP initialize through tunnel
curl -X POST .../mcp -H "Accept: application/json, text/event-stream" -d '...'
# {"result":{"protocolVersion":"2024-11-05",...}}
```

### Key Learnings

1. **Electron bundling breaks module paths**: Can't rely on npm package default paths inside Obsidian
2. **Quick Tunnels are truly zero-config**: No Cloudflare account needed
3. **Binary installation is idempotent**: Package handles version checking
4. **URL changes on restart**: Users must reconfigure Claude after Obsidian restart

### Statistics

- **1 npm package** added (cloudflared)
- **~150 lines** of tunnel code
- **4 new settings** (enableTunnel, tunnelUrl, status, UI elements)
- **~50MB** cloudflared binary (downloaded on first use)

### Next Steps

- Authentication token enforcement for tunnel
- WhatsApp/Telegram bot integration
- Permanent URLs via Named Tunnel (documentation)

---

## 2026-02-01 - Token Authentication for Remote Access

**Objective**: Implement simple token-based authentication to protect the MCP endpoint when exposed via Cloudflare tunnel.

### What We Built

A simplified authentication system that protects remote access with a token, replacing the initial OAuth 2.0 implementation that proved incompatible with Claude Desktop.

**Key Features:**

- **Query Parameter Token**: Access via `?token=xxx` in the URL
- **Authorization Header**: Also accepts `Authorization: Bearer xxx`
- **Auto-Generate Token**: Token created automatically when enabling auth
- **Settings UI**: Token field with regenerate button under Remote Access section
- **URL Integration**: MCP URL displays with token included when auth is enabled

### The Journey

**Initial Approach: OAuth 2.0 Client Credentials**

Started implementing full OAuth 2.0 Client Credentials Grant:
- Added `/.well-known/oauth-authorization-server` metadata endpoint
- Implemented `/oauth/token` endpoint
- Generated client ID and secret on first run
- Token issuance with expiration

**The Problem: Claude Desktop OAuth Requirements**

Discovered through web research that Claude Desktop requires OAuth 2.1 Authorization Code flow with PKCE, not the simpler Client Credentials grant we implemented. Claude's MCP authentication is designed for delegated authorization scenarios, not machine-to-machine authentication.

Key findings:
- Claude expects a full OAuth 2.1 flow with user consent screens
- Client Credentials grant (machine-to-machine) isn't supported
- Known bugs with OAuth in Claude Desktop as of late 2025

**The Pivot: Simple Token Authentication**

Decided to simplify to a query parameter token approach:

1. **Security Trade-off**: Query params in HTTPS are encrypted in transit, but may appear in logs. Acceptable for personal vaults.
2. **Dual Support**: Accept token via query param OR Authorization header for flexibility
3. **UI Integration**: Token shown in the MCP URL for easy copy-paste

### Technical Achievements

**Token Validation Logic:**

```typescript
private validateAuth(req: IncomingMessage): boolean {
  const expectedToken = this.settings.authToken;

  // Check query parameter
  const url = new URL(req.url || '', `http://localhost:${port}`);
  const queryToken = url.searchParams.get('token');
  if (queryToken === expectedToken) return true;

  // Check Authorization header
  const authHeader = req.headers['authorization'];
  if (authHeader?.split(' ')[1] === expectedToken) return true;

  return false;
}
```

**Settings UI Changes:**

- Moved "Require Authentication" toggle under Remote Access section
- Only shows when tunnel is enabled (auth without tunnel is pointless)
- Token field with regenerate button appears when auth is enabled
- MCP URL automatically includes `?token=xxx` when both tunnel and auth are enabled

### Key Learnings

1. **Claude OAuth is complex**: Claude Desktop expects full OAuth 2.1 with PKCE, not simple client credentials
2. **Simple beats complex**: For personal use, a query parameter token is perfectly adequate
3. **HTTPS protects query params**: Query strings are encrypted in transit, only visible in logs
4. **UI flow matters**: Showing the complete URL with token makes copy-paste seamless

### Statistics

- **~100 lines removed** (OAuth complexity)
- **~50 lines added** (simple token auth)
- **1 new setting** (moved authToken under Remote Access)
- **Net simplification**: Fewer endpoints, cleaner code

### Next Steps

- WhatsApp/Telegram bot integration
- Permanent URLs via Named Tunnel (documentation)
- Consider rate limiting for public exposure

---

## 2026-02-01 - GitHub Repository & First Release

**Objective**: Publish the Witness plugin to GitHub and create the first release for BRAT installation.

### What We Built

Made Witness publicly available on GitHub with a proper release for easy installation.

**Repository**: [github.com/jawache/witness](https://github.com/jawache/witness)

**Release**: v0.1.0 - Initial Release

### Release Contents

The v0.1.0 release includes:

- `main.js` - Compiled plugin code (~2MB)
- `manifest.json` - Plugin metadata

**Features in this release:**

- 9 MCP tools (read_file, write_file, list_files, edit_file, search, find_files, move_file, execute_command, get_vault_context)
- Cloudflare Quick Tunnel for remote access
- Token authentication for secure remote connections
- Claude Desktop integration via mcp-remote bridge
- File-based logging
- Full settings UI

### Installation via BRAT

Users can now install Witness easily using the BRAT plugin:

1. Install BRAT from Community Plugins
2. Add Beta Plugin: `jawache/witness`
3. Enable Witness in Community Plugins

BRAT handles downloading the release assets and installing them in the correct location.

### Documentation Updates

Updated README.md with:

- BRAT installation instructions (recommended method)
- Manual installation from releases
- Build from source instructions
- Clear separation of installation methods

### Statistics

- **1 GitHub repository** created
- **1 release** (v0.1.0) published
- **2 release assets** (main.js, manifest.json)
- **README.md** updated with new installation options

### Next Steps

- Submit to Obsidian Community Plugins (requires review)
- WhatsApp/Telegram bot integration
- Permanent URLs via Named Tunnel

---

## 2026-02-01 - Semantic Search Implementation (PAUSED)

**Objective**: Add semantic search capability that finds files by meaning, not just keywords, leveraging Smart Connections embeddings.

**Status**: ⏸️ PAUSED - ONNX WASM runtime doesn't initialize properly in Obsidian's Electron environment. Code preserved in `feature/semantic-search` branch.

### What We Built

Implemented a `semantic_search` MCP tool that:
- Generates query embeddings using transformers.js with `TaylorAI/bge-micro-v2` model
- Loads pre-computed embeddings from Smart Connections' `.smart-env/multi/*.ajson` files
- Calculates cosine similarity between query and document vectors
- Returns ranked list of semantically similar files

### The Journey

**Research Phase: Smart Connections Integration**

Initially explored calling Smart Connections APIs directly, but discovered:
- Obsidian commands are fire-and-forget (no return values)
- Smart Connections doesn't expose a programmatic search API
- Other MCP servers that integrate with SC all read the `.ajson` files directly

This led to the decision to bundle transformers.js and generate query embeddings ourselves.

**The Build Challenge: Native ONNX Bindings**

First attempt with `@xenova/transformers` failed to build:
- ES2018 target doesn't support BigInt literals (used by ONNX)
- Native `.node` files can't be bundled by esbuild
- Same issues with `@huggingface/transformers`

**Solution: Browser Platform + WASM**

Updated esbuild configuration:
- Changed `platform` from "node" to "browser"
- Upgraded `target` to "es2020" for BigInt support
- Added `conditions: ["browser", "import"]` for WASM version
- Aliased `onnxruntime-node` to `onnxruntime-web`
- Marked native modules as external

This forces transformers.js to use the WebAssembly backend instead of native ONNX bindings, which works in Obsidian's Electron environment.

### Implementation Details

**Helper Methods:**
- `initEmbedder()` - Lazy-loads transformers.js pipeline on first use
- `cosineSimilarity()` - Vector similarity calculation
- `loadSmartConnectionsEmbeddings()` - Parses SC's `.ajson` format with caching
- `clearEmbeddingsCache()` - Manual cache invalidation if needed

**The semantic_search Tool:**
```typescript
semantic_search(query: string, limit?: number)
// Returns: List of files ranked by semantic similarity
// Example: "productivity systems" → finds notes about GTD, time management, etc.
```

### Technical Achievements

- Successfully bundled transformers.js (4.2MB) for Obsidian
- Compatible with Smart Connections' embedding format
- Lazy loading prevents startup delay
- Embeddings cached for fast subsequent searches

### Key Learnings

1. **Platform matters**: esbuild's `platform: "browser"` + conditions can force WASM builds
2. **ES target versions**: BigInt requires ES2020 minimum
3. **Smart Connections format**: AJSON files store embeddings keyed by `TaylorAI/bge-micro-v2`
4. **Obsidian = Electron**: Browser APIs available, but Node.js require() still works

### Statistics

- **1 new MCP tool**: semantic_search
- **4 helper methods** added
- **Bundle size**: 4.2MB (increased from transformers.js)
- **10 total MCP tools** now available

### Why Paused

Despite successful bundling, the ONNX WASM runtime fails to initialize in Obsidian's Electron environment:

```text
TypeError: Cannot read properties of undefined (reading 'create')
at createInferenceSession
```

The model downloads correctly but `InferenceSession.create()` fails. The WASM files aren't loading properly in Electron's sandboxed environment.

### Code Preserved

All semantic search code is in the `feature/semantic-search` branch for future work when we find a solution.

### Potential Future Approaches

- Run embeddings in a separate Node.js process
- Use a different model format (GGML/llama.cpp)
- Wait for better Electron/WASM compatibility
- External embedding service

---

## 2026-02-03 - Semantic Search WASM Deep Dive

**Objective**: Get WASM-based embeddings working in Obsidian for semantic search

### What We Tried

Continued investigation into running transformers.js/ONNX in Obsidian's Electron environment. Systematically tested multiple approaches:

1. **Web Worker with bundled transformers.js**
   - Model downloads successfully (0-100%)
   - Fails at ONNX session creation: "no available backend found"

2. **Direct main thread with bundled transformers.js**
   - TypeScript errors with fileURLToPath resolution
   - Electron's hybrid Node.js/browser environment confuses module resolution

3. **Dynamic import from CDN**
   - `import('https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2')`
   - Works in Electron's renderer process
   - Model downloads successfully
   - Same ONNX session creation failure: "Cannot read properties of undefined (reading 'create')"

4. **Preloading onnxruntime-web separately**
   - Load onnxruntime-web via script tag before transformers.js
   - Set WASM paths explicitly
   - Still fails at InferenceSession.create()

5. **Various env configurations**
   - `env.allowLocalModels = false`
   - `env.useBrowserCache = true`
   - `env.backends.onnx.wasm.wasmPaths = CDN_URL`
   - None resolved the core issue

### Root Cause Analysis

The fundamental problem is that **Obsidian's Electron renderer process is a hybrid Node.js/browser environment** that confuses ONNX runtime's backend selection:

1. ONNX detects Node.js APIs are available → tries Node backend
2. Node backend requires native binaries → fails
3. Falls back to WASM backend
4. WASM backend can't initialize properly because of hybrid environment
5. `InferenceSession.create` becomes undefined

This is a **known limitation** with transformers.js in Electron environments. The library is designed for either pure Node.js OR pure browser, not Electron's hybrid.

### THE SOLUTION: Iframe Isolation

After examining the Smart Connections plugin codebase (which does WASM embeddings successfully), found the key insight: **use a hidden iframe to provide a clean browser context**.

**How it works:**
1. Create a hidden iframe with `srcdoc` containing a module script
2. The iframe runs in a pure browser context without Node.js APIs
3. Load transformers.js from CDN inside the iframe
4. Communicate via `postMessage` between main plugin and iframe
5. WASM initializes successfully in the clean browser environment!

**Implementation:**
```typescript
// Create hidden iframe
this.iframe = document.createElement('iframe');
this.iframe.style.display = 'none';
this.iframe.srcdoc = `
  <script type="module">
    const transformers = await import('https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.8.0');
    // ... pipeline initialization works here!
  </script>
`;
document.body.appendChild(this.iframe);
```

**Results:**
- ✅ Model downloads successfully
- ✅ WASM/ONNX runtime initializes
- ✅ Embeddings generated (384 dimensions)
- ✅ Sub-second response time after initial load

### Code Changes

- Created `embedding-service-iframe.ts` with iframe-based approach
- Uses `@huggingface/transformers@3.8.0` from CDN
- Tries WebGPU first, falls back to WASM
- Updated `main.ts` to use `EmbeddingServiceIframe`

### Key Learning

**The iframe isolation pattern is the solution for running WASM in Obsidian plugins.** The iframe provides a clean browser environment where:
- No Node.js APIs pollute the global scope
- Module resolution follows browser rules
- WASM backend initialization works correctly

Credit to Smart Connections for pioneering this approach!

### Next Steps

1. ✅ WASM embeddings working via iframe
2. Phase B: Implement storage & indexing in .witness/
3. Phase C: Complete semantic_search tool with actual document search
4. Phase D: Settings UI for semantic search
5. Phase E: Obsidian Leaf View UI

---

## 2026-02-04 - Semantic Search Complete: Storage, Indexing & Search

**Objective**: Complete the semantic search implementation with document indexing, storage, and actual search functionality.

### What We Built

Completed the full semantic search pipeline:

1. **EmbeddingIndex** (`src/embedding-index.ts`)
   - Storage in `.witness/embeddings/` folder
   - Index metadata tracking model, version, document count
   - Per-file vector storage in `vectors/` subdirectory
   - Cosine similarity search with filtering by tags/paths
   - Incremental update support

2. **DocumentIndexer** (`src/document-indexer.ts`)
   - Hierarchical chunking: document-level + H2 section embeddings
   - Front matter extraction (tags, title)
   - Content hashing for change detection
   - Progress callbacks for UI feedback

3. **MCP Tools**
   - `semantic_search` - Find documents by meaning with filters
   - `index_documents` - Build/update the embedding index

4. **Incremental Updates**
   - File change listeners (`modify`, `delete`, `rename`)
   - Automatic re-indexing on file changes
   - Skip unchanged files during batch indexing

### The Journey

**Challenge: Wrong Test Vault**

Spent significant time debugging why `index_documents` tool wasn't appearing. Discovered there were TWO vaults:
- `test-vault/` - where we were copying files
- `test/vault/` - the actual vault open in Obsidian

After copying to the correct location and restarting Obsidian, everything worked immediately.

**Testing the Full Pipeline:**

```bash
# Initialize session
curl -X POST http://localhost:3001/mcp ...

# Index documents - SUCCESS!
{"text":"Indexing complete!\n\n- Indexed: 8 documents\n- Skipped (unchanged): 0\n- Errors: 0\n\nModel: TaylorAI/bge-micro-v2 (384 dimensions)"}

# Search by meaning - SUCCESS!
{"text":"Found 9 result(s) for: \"chaos and order philosophy\"\n\n1. **move-conflict-source** (50.5%)\n..."}
```

The search returns both document-level and section-level results with similarity percentages.

### Achievements

- **Iframe Pattern Works**: transformers.js runs successfully in hidden iframe
- **384-dimension embeddings**: Using TaylorAI/bge-micro-v2 model
- **Sub-second queries**: After initial model load, search is fast
- **Hierarchical results**: Section headings with line numbers returned
- **Filter support**: Can filter by tags and folder paths

### Learnings

1. **Always verify the correct vault**: Development vs test vaults can cause confusion
2. **Obsidian requires full restart**: Copying files isn't enough - JS must be reloaded
3. **Iframe isolation is the key**: Clean browser context for WASM initialization
4. **postMessage for communication**: Simple and reliable across iframe boundary

### Session Stats

- **3 new source files** created
- **~600 lines** of new TypeScript
- **2 new MCP tools** (semantic_search, index_documents)
- **14 total MCP tools** now available
- **8 documents indexed** in test vault

### Files Changed

- `src/embedding-service-iframe.ts` - Iframe WASM embeddings (created earlier)
- `src/embedding-index.ts` - NEW: Storage and search
- `src/document-indexer.ts` - NEW: Document processing
- `src/main.ts` - Updated with new tools and file listeners
- `README.md` - Updated feature list and roadmap
- `CLAUDE.md` - Updated phase status and documentation

### What's Next

- Phase D: Settings UI for semantic search (exclude paths, index status)
- Phase E: Obsidian Leaf View for visual search interface
- Consider: Background indexing on vault open

---

*End of log entry*

## 2026-02-04 - Smart Connections Integration

**Objective**: Replace custom iframe-based embedding indexing with Smart Connections' pre-built embeddings for semantic search.

### The Problem

The custom embedding approach (iframe + transformers.js + WASM) worked but had stability issues at scale. When indexing a vault with ~2000 documents, approximately 10% of files (~200) would fail to index due to WASM memory corruption. The iframe reset mechanism helped but didn't fully solve it. Rather than fight WASM instability, we pivoted to reading embeddings from the Smart Connections plugin, which has already solved these problems with its mature indexing system.

### What We Built

- **SmartConnectionsReader** (`src/smart-connections-reader.ts`): New class that reads and caches embeddings from Smart Connections' `.smart-env/multi/*.ajson` files
  - Validates SC is installed with correct model (`TaylorAI/bge-micro-v2`)
  - Parses AJSON format (append-only JSON, one entry per line with trailing commas)
  - Incremental caching using mtime tracking per SC file
  - Cosine similarity search against cached vectors

- **Updated `semantic_search` tool**: Now uses SmartConnectionsReader for document embeddings while keeping iframe embedding service for query embeddings only

- **Removed `index_documents` tool**: SC handles all indexing, so this tool is no longer needed

- **Cleaned up old embedding code**: Removed 5 source files (~1,450 lines) that are no longer needed

### The Journey

**Feature branch preservation**: Before starting, we preserved all the iframe embedding work on the `feature/iframe-embeddings` branch in case we ever need it again.

**SC file format discovery**: Smart Connections stores embeddings in `.smart-env/multi/*.ajson` files. The AJSON format is append-only JSON with one entry per line. Each line looks like:
```
"smart_sources:path/to/file.md": {"path":"path/to/file.md","embeddings":{"TaylorAI/bge-micro-v2":{"vec":[...384 floats...]}},...},
```
Key gotcha: lines end with a trailing comma which must be stripped before JSON parsing.

**mtime caching bug**: The first implementation tried to map SC filenames back to vault paths for cache lookup (SC uses `!` for hidden paths like `.obsidian/`, while our conversion used `_`). This meant cache lookups failed and every search re-read all 4000+ files from disk (~7 seconds). Fixed by tracking mtimes directly keyed by SC file path, with a separate `scFileToVaultPath` map. After fix: cached searches complete in ~265ms.

**Deleted files cleanup**: Also removed the esbuild worker configuration since we no longer build a separate Web Worker bundle.

### Technical Details

**Architecture**:
```
semantic_search request
    → SmartConnectionsReader.validate() - check SC config & model
    → SmartConnectionsReader.loadEmbeddings() - incremental, mtime-based
    → EmbeddingServiceIframe.embed(query) - WASM query embedding
    → SmartConnectionsReader.search() - cosine similarity
    → Ranked results
```

**Performance on main vault (4,097 documents)**:
- First search: ~14s (load all embeddings from disk + model init)
- Subsequent searches: ~265ms (mtime checks + query embedding + search)
- Memory: ~7MB for 4097 cached vectors (384 floats × 4 bytes × 4097)
- Search execution: <10ms for cosine similarity against all vectors

**Files removed** (1,451 lines deleted):
- `src/embedding-index.ts` (418 lines) - Custom storage
- `src/document-indexer.ts` (428 lines) - Custom indexing
- `src/embedding-service.ts` (232 lines) - Web Worker approach
- `src/embedding-service-direct.ts` (227 lines) - Direct approach
- `src/embedding-worker.ts` (146 lines) - Worker file

**Files kept**:
- `src/embedding-service-iframe.ts` - Still used for query embedding generation

### Key Learnings

1. **Leverage existing plugins**: Smart Connections has years of development solving WASM/ONNX stability issues. Reading their embeddings is far more reliable than reimplementing indexing.
2. **AJSON trailing commas**: SC's append-only JSON format has trailing commas on each line - must strip before parsing.
3. **SC filename conventions**: Files starting with `.` get `!` prefix in SC filenames (e.g., `.obsidian/` → `!obsidian_`). Don't try to reverse-engineer this; track by SC file path directly.
4. **mtime-based caching**: Track mtimes keyed by the actual file path you're checking (SC file path), not by a derived/converted path. Simple and reliable.

### Session Stats

- **1 new source file** created (`src/smart-connections-reader.ts`, ~360 lines)
- **5 source files** deleted (~1,450 lines)
- **Net: ~1,090 lines removed** while adding the same functionality
- **13 MCP tools** (down from 14 - removed `index_documents`)
- **4,097 documents** successfully searched in main vault

### Files Changed

- `src/smart-connections-reader.ts` - NEW: SC file reading and caching
- `src/main.ts` - Updated semantic_search, removed index_documents
- `esbuild.config.mjs` - Removed worker build configuration
- `docs/features/smart-connections-integration.md` - NEW: Feature specification
- `src/embedding-index.ts` - DELETED
- `src/document-indexer.ts` - DELETED
- `src/embedding-service.ts` - DELETED
- `src/embedding-service-direct.ts` - DELETED
- `src/embedding-worker.ts` - DELETED

### What's Next

- Fix first-search latency (~14s for 4000 docs) - consider background preloading on plugin start
- Settings UI for semantic search (exclude paths, index status)
- Obsidian Leaf View for visual search interface

---

*End of log entry*

## 2026-02-05 - Named Tunnel & Primary Machine

**Objective**: Replace ephemeral Quick Tunnel URLs with permanent Named Tunnel support, and add a Primary Machine feature for multi-device Obsidian Sync setups.

### What We Built

Two major features for the remote access system:

1. **Cloudflare Named Tunnel Support** - Permanent URLs using your own domain
2. **Primary Machine Designation** - Only one machine runs the tunnel when syncing across devices

### The Journey

**Named Tunnel Implementation**

The user was tired of Quick Tunnel URLs changing every time Obsidian restarts. They had already created a Named Tunnel in the Cloudflare dashboard pointing `witness.asim.dev` to `localhost:3456`.

The `cloudflared` npm package provides two APIs:
- `Tunnel.quick(url)` - Quick tunnel with random trycloudflare.com URL
- `Tunnel.withToken(token)` - Named tunnel using pre-configured dashboard settings

Key discovery: Named tunnels do NOT emit a `url` event. That event is specifically for trycloudflare.com URLs where the URL isn't known in advance. Named tunnels emit a `connected` event instead, since the URL is already configured in the Cloudflare dashboard. This required listening for `connected` instead of `url` to update tunnel status.

**Settings UI Updates:**

- Added tunnel type dropdown: Quick vs Named
- Added password-masked token field (300px wide for long JWT tokens)
- Added editable tunnel URL field for the user's public hostname
- MCP URL display automatically constructs the full URL with /mcp path and ?token= parameter

**The Port Mismatch Discovery**

Initial testing failed because the Cloudflare tunnel was configured for `localhost:3456` but the plugin was running on port 3000. Changed the port in settings to match.

**The /health 404 Mystery**

After connecting the tunnel, `/health` returned 404 while `/mcp` returned 401 (correct auth error). The cause: the Cloudflare tunnel ingress rules were path-restricted to `/mcp` only. After the user removed the path restriction in the dashboard, all endpoints worked through the tunnel.

**Orphaned Process Cleanup**

Discovered 17 orphaned `cloudflared tunnel --url http://localhost:3000` processes from previous Quick Tunnel sessions that weren't properly cleaned up on Obsidian restart. Killed them all.

**Multi-Device Problem**

The user asked: "What happens if multiple machines with Obsidian Sync all have the same tunnel token?" Answer: Cloudflare treats them as multiple connectors for the same tunnel and round-robins traffic between them. Since each machine has a different vault state, this produces unpredictable results.

**Primary Machine Feature**

Solution: Added `tunnelPrimaryHost` setting that stores `os.hostname()` of the designated machine. At the top of `startTunnel()`, the plugin checks if the current hostname matches. If not, it silently skips starting the tunnel.

Settings UI for primary machine:
- Shows current host vs configured host
- "Set as primary" button (disabled if already primary)
- "x" button to clear (allow all machines)
- Warning color when current machine is NOT the primary

**Mobile Considerations**

Obsidian mobile (iOS/Android) cannot run the HTTP server or cloudflared binary. The tunnel and MCP server features are desktop-only. Mobile devices access the vault as clients through the tunnel URL.

### Technical Details

**New Settings:**
```typescript
tunnelType: 'quick' | 'named';   // Tunnel mode
tunnelToken: string;              // Cloudflare tunnel JWT token
tunnelPrimaryHost: string;        // Hostname of primary machine
```

**Named Tunnel Connection:**
```typescript
if (isNamed) {
    this.tunnelProcess = Tunnel.withToken(this.settings.tunnelToken);
    this.tunnelProcess.once('connected', async (connection) => {
        this.tunnelStatus = 'connected';
        // URL comes from user settings, not from event
    });
}
```

**Primary Host Check:**
```typescript
const currentHost = os.hostname();
if (this.settings.tunnelPrimaryHost &&
    this.settings.tunnelPrimaryHost !== currentHost) {
    this.logger.info(`Tunnel skipped: not primary host`);
    return;
}
```

### Key Learnings

1. **Named tunnels don't emit `url` events**: Only Quick Tunnels (trycloudflare.com) emit the `url` event. Named tunnels emit `connected` with location/IP info.
2. **Cloudflare ingress rules matter**: Path restrictions in the tunnel config affect which endpoints are accessible. Keep it open or match all your endpoints.
3. **Round-robin is the default**: Multiple cloudflared connectors on the same tunnel = load balancing. Not what you want for personal vaults.
4. **`os.hostname()` for machine identity**: Simple and reliable way to identify which machine is which across Obsidian Sync.
5. **Orphan processes accumulate**: Quick Tunnels from previous sessions may not be cleaned up on crash/force-quit. Consider periodic cleanup.

### README Overhaul

Rewrote the entire Remote Access section with:
- Option A: Quick Tunnel (easy, temporary)
- Option B: Named Tunnel with 3-step Cloudflare dashboard guide
- Multiple Devices section with Primary Machine explanation
- Mobile Devices section explaining desktop-only limitations
- Security Notes section

### Statistics

- **3 new settings** added to WitnessSettings
- **~60 lines** of tunnel code changes
- **~80 lines** of settings UI additions
- **README** Remote Access section completely rewritten
- **17 orphaned processes** cleaned up
- **1 successful end-to-end test** through `witness.asim.dev`

### Files Changed

- `src/main.ts` - Named tunnel support, primary host check, settings UI
- `README.md` - Comprehensive remote access documentation
- `CLAUDE.md` - Updated with session learnings
- `manifest.json` - Version bump to 0.4.0
- `package.json` - Version bump to 0.4.0

### What's Next

- WhatsApp/Telegram bot integration (Phase 2 remaining)
- Phase 4: Heartbeat scheduler, chaos monitoring
- Consider: automatic orphan process cleanup on startup

---

*End of log entry*

## 2026-02-05 - Dataview Integration & Orientation Consolidation

**Objective**: Integrate the Dataview plugin's query engine into Witness MCP tools, consolidate the main vault's orientation files into a single comprehensive document, and refine the knowledge-saving workflow.

### What We Built

1. **`dataview_query` MCP tool** — Execute DQL queries directly from an AI client
   - Supports markdown and JSON output formats
   - Structured data: `dvApi.query()` with Link-to-string conversion
   - Rendered tables: `dvApi.queryMarkdown()` for human-readable output
   - Always registered at startup; checks Dataview availability at call time

2. **`read_file` render parameter** — Optional `render: true` flag that resolves Dataview codeblocks before returning content

3. **`get_orientation` auto-rendering** — Orientation document always has its Dataview queries resolved, so the AI sees live data (prompt tables, template lists) instead of raw codeblocks

4. **Consolidated ORIENTATION.md** — Merged three separate context files in the main vault into one comprehensive document covering vault philosophy, knowledge collections, templates, prompts, heartbeat, writing style, and the full knowledge-saving workflow

5. **Knowledge-saving workflow** — Detailed "Saving Knowledge to the Vault" section with:
   - Existence checking (text + semantic search before creating)
   - Citation-by-default policy (footnotes for external sources without being asked)
   - Internal wiki-links via semantic search (knowledge-to-knowledge only)
   - Frontmatter references for provenance
   - Summary table of all 5 link types

6. **Session skills** — Updated `/wrap-up` to include git push, created `/release` for GitHub releases with version bumps

### The Journey

The session started with Dataview research — confirming that the `dvApi.queryMarkdown()` and `dvApi.query()` APIs were accessible from within Obsidian's plugin context. The key architectural insight was that Witness has a unique advantage: it runs *inside* Obsidian, so it can call Dataview's API directly rather than scraping rendered HTML.

The first implementation hit a plugin load-order bug: Dataview hadn't initialised yet when Witness registered its tools at startup. The conditional `if (this.isDataviewAvailable())` check silently skipped registration entirely. The fix was straightforward — always register the tool, check availability at call time, and return a helpful error if Dataview isn't loaded.

The orientation consolidation was more involved. Three separate files (root ORIENTATION.md, knowledge ORIENTATION.md, and relevant CLAUDE.md sections) were merged into a single document. Multiple rounds of refinement followed — removing sections that belong in system prompts, expanding the citation and linking rules, and establishing the "citations by default" policy.

### Technical Achievements

- **15 MCP tools** now available (was 13)
- **31 integration tests** passing (8 new Dataview tests)
- Regex-based Dataview codeblock detection: `/```dataview\n([\s\S]*?)```/g`
- Link object serialisation for JSON format output
- Test vault now includes Dataview plugin and 3 topic files for testing

### Key Learnings

- **Plugin load order matters**: Always register tools unconditionally and check runtime availability in the handler. Obsidian doesn't guarantee plugin load order.
- **Dataview API is clean**: `queryMarkdown()` returns `{ successful: boolean, value: string, error?: string }` — no parsing needed.
- **Orientation files benefit from live data**: Having Dataview queries in the orientation document means the AI always sees current prompt and template lists without manual updates.

### Statistics

- Files changed: 5 modified, 6 new
- Lines added: ~350
- New MCP tools: 1 (`dataview_query`)
- New tool parameters: 1 (`read_file.render`)
- New integration tests: 8
- Total integration tests: 31

### What's Next

- Semantic search feature implementation (Phase A-E from feature spec)
- WhatsApp/Telegram bot integration
- Phase 4: Heartbeat scheduler, chaos monitoring

---

*End of log entry*

## 2026-02-05 - Claude Code Configuration & Desktop-Only Flag

**Objective**: Set up reusable Claude Code configuration for use across projects, and mark the plugin as desktop-only.

### What We Built

- **User-level Claude Code skills** (`~/.claude/skills/`):
  - `/wrap-up` — session wrap-up protocol (DEVLOG, docs, commit, push)
  - `/release` — version bump, build, GitHub release creation
  - `/init-project` — scaffold standard project files (CLAUDE.md, DEVLOG, README.md, TODO.md, docs/)
- **User-level CLAUDE.md** (`~/.claude/CLAUDE.md`) — shared conventions: project structure, DEVLOG format, TODO.md usage, feature file specs, commit style, British English preference
- **User-level settings** (`~/.claude/settings.json`) — permissive permissions (Bash(*), Read, Edit, Write, WebSearch, WebFetch) so every project gets them by default
- **Desktop-only flag** — set `isDesktopOnly: true` in manifest.json since the plugin runs an HTTP server and cloudflared binary

### The Journey

Started with the question of how to share Claude Code configuration across projects. Discovered the configuration hierarchy: user-level (`~/.claude/`) vs project-level (`.claude/`). Converted the existing JSON skill files to the preferred markdown SKILL.md format with YAML frontmatter, generalised them so they're not Witness-specific, and placed them at user level.

Also captured the user's project conventions: TODO.md linking to feature specs in `docs/features/`, `docs/spec.md` for original specifications, and the pattern of ending feature discussions with a spec file.

### Key Learnings

- Claude Code skills live in `~/.claude/skills/<name>/SKILL.md` for user-level (all projects) or `.claude/skills/<name>/SKILL.md` for project-level
- Both `.claude/commands/` (legacy) and `.claude/skills/` work, but skills is the current standard
- Skills use markdown with YAML frontmatter, not JSON — `allowed-tools` in frontmatter grants auto-approved permissions
- User-level `~/.claude/CLAUDE.md` applies to all projects — good for shared conventions
- User-level `~/.claude/settings.json` applies globally — no need for per-project settings files if permissions are the same

### Statistics

- 5 files created at user level (~/.claude/)
- 1 file modified in repo (manifest.json)
- Skills converted from JSON to markdown format

### Next Steps

- Test `/init-project` in a new project directory
- Test `/wrap-up` and `/release` in a fresh session
- Consider adding more shared skills as patterns emerge

---

*End of log entry*

## 2026-02-05 - Ollama + Orama: Own the Embedding Index

**Objective**: Replace Smart Connections + iframe WASM embedding approach with Ollama for embedding generation and Orama for vector storage. Own the entire embedding index.

### What We Built

1. **OllamaProvider** (`src/ollama-provider.ts`, ~110 lines) — HTTP client for Ollama's `/api/embed` endpoint
   - Batch embedding support (multiple texts in one call)
   - Model availability checking (`/api/tags`)
   - Dimension lookup for known models
   - Default: `nomic-embed-text` (768 dimensions, 274MB)

2. **VectorStore** (`src/vector-store.ts`, ~250 lines) — Orama-backed vector database
   - Schema: path, title, mtime, embedding vector
   - Single-file persistence at `.witness/index.orama`
   - Incremental indexing: only re-embeds files with changed mtime
   - Batch indexing with progress callbacks
   - Cosine similarity search with path filtering

3. **Updated `semantic_search` tool** — Lazy-initialises Ollama + Orama on first use
   - Checks Ollama availability, returns helpful error if not running
   - Auto-indexes stale files before searching
   - Persists index to disk after indexing

4. **Removed Smart Connections integration** — Deleted `src/smart-connections-reader.ts` (343 lines) and `src/embedding-service-iframe.ts` (540 lines). Net deletion of ~883 lines of fragile code.

### The Journey

The session started with revisiting the embedding strategy. The iframe WASM approach worked but was brittle — ~400 lines of code handling WebGPU detection, fp16/fp32 fallback, WASM fallback, throttling, and iframe lifecycle. Smart Connections dependency tied us to another plugin's proprietary `.ajson` format, which isn't sustainable for a public plugin.

**Ollama as the answer**: Since the user already runs Ollama on the same machine, we can replace both SC reading AND iframe WASM with simple HTTP calls to `localhost:11434/api/embed`. No WASM, no iframe, no proprietary formats.

**Storage: Orama over individual JSON files**: The earlier custom embedding index used one JSON file per document, causing multi-second load times on large vaults. Orama provides a pure JS embedded search engine (<2kb bundled) that serialises the entire database to a single JSON file. Load once, search in microseconds.

**The implementation went smoothly**: Created `OllamaProvider` and `VectorStore` as clean, focused classes. Updated `src/main.ts` to use them instead of SC/iframe. Built successfully after fixing Orama's internal type casting (needed `as unknown as VaultDocument`).

**End-to-end test**: Launched Obsidian with the test vault, initialised an MCP session, and called `semantic_search` with query "test vault integration". Got 5 results back:

1. README.md (66.9%)
2. subfolder/nested.md (43.0%)
3. test-read.md (40.6%)
4. topics/carbon-accounting.md (38.4%)
5. dataview-test.md (38.1%)

### Key Learnings

1. **Simple HTTP > iframe WASM**: Replacing ~540 lines of iframe/WASM/WebGPU code with a 20-line HTTP fetch to Ollama. The complexity difference is staggering.
2. **Orama is excellent**: Pure JS, zero dependencies, vector + full-text support, single-file serialisation. Perfect for Obsidian plugins.
3. **Own your index**: Depending on another plugin's internal data format is fragile. Generating and storing embeddings ourselves gives full control.
4. **Ollama batch API**: The `/api/embed` endpoint accepts an array of inputs, reducing round-trips for bulk indexing.

### Statistics

- **2 new source files** created (~360 lines)
- **2 source files** deleted (~883 lines)
- **Net: ~520 lines removed** while keeping the same functionality
- **1 npm package** added (`@orama/orama`)
- **Bundle size**: 2.2MB (down from previous builds with transformers.js overhead)
- **5 test results** returned successfully from end-to-end test

### Files Changed

- `src/ollama-provider.ts` — NEW: Ollama HTTP client
- `src/vector-store.ts` — NEW: Orama vector store
- `src/main.ts` — Updated imports, instance vars, semantic_search handler
- `src/smart-connections-reader.ts` — DELETED
- `src/embedding-service-iframe.ts` — DELETED
- `docs/features/ollama-integration.md` — NEW: Feature specification
- `TODO.md` — Added Ollama integration task
- `package.json` — Added @orama/orama dependency
- `manifest.json` — isDesktopOnly: true (both demo + test vaults)

### What's Next

- Integration tests for the new Ollama/Orama semantic search
- Settings UI for Ollama configuration (base URL, model selection)
- Background indexing on vault open
- Progress indicator during initial index build

---

*End of log entry*

## 2026-02-07 - Fixing Embedding Quality: Context Limits, Task Prefixes, and Short Document Noise

**Objective**: Debug and fix the 565 embedding failures with nomic-embed-text, then systematically fix search quality issues uncovered during real-world testing on a 4,097-document vault.

### What We Built

- Dynamic model info resolution via Ollama's `/api/show` endpoint
- Model-specific task prefixes for nomic-embed-text and mxbai-embed-large
- Minimum content length filter (configurable, default 50 chars) to suppress short document noise
- Race condition fixes in the settings UI async lifecycle
- Fixed Clear Index to work even when VectorStore hasn't been loaded
- Comprehensive documentation of embedding model behaviour and gotchas

### The Journey

This session was a deep debugging journey into why semantic search was returning poor results. It started with a simple symptom — 565 out of ~4,000 files failing to embed — and ended with a thorough understanding of how embedding models actually work under the hood.

**Chapter 1: The 565 Failures**

After switching from mxbai-embed-large to nomic-embed-text, 565 files consistently failed with Ollama returning 400 "index length exceeded context length". We had already added `truncate: true` and client-side pre-truncation in the previous session, so why were files still failing?

The breakthrough came from querying Ollama's `/api/show` endpoint directly:

```bash
curl -s http://localhost:11434/api/show -d '{"model":"nomic-embed-text"}' | jq '.model_info'
```

This revealed `nomic-bert.context_length: 2048` — but our hardcoded `MODEL_CONTEXT_TOKENS` had `8192` for nomic-embed-text, taken from the Modelfile's `num_ctx` parameter. These are fundamentally different things: `num_ctx` is a runtime parameter for generative models, but BERT-based embedding models have a fixed architecture context window baked into their weights. For nomic-embed-text, that's 2048 tokens, not 8192.

With `maxChars = 8192 * 2 = 16384`, we were sending documents up to 16K characters — far exceeding the actual 4096-character limit (2048 tokens * 2 chars/token). Fixing the constant to 2048 immediately resolved all 565 failures.

**Chapter 2: Dynamic Resolution**

Hardcoded constants are fragile. The user rightly pointed out that if Ollama's `/api/show` provides the real values, we should use them. We added `resolveModelInfo()` to OllamaProvider, which queries `/api/show` once at startup and caches both `embedding_length` (dimensions) and `context_length` (context window). The hardcoded maps now serve as fallbacks when Ollama is unreachable.

**Chapter 3: Clear Index Doesn't Actually Clear**

Testing revealed that "Clear Index" didn't work after a plugin restart. The bug: `clearIndex()` checked `if (this.vectorStore)` — but after a restart, `vectorStore` is null (it's lazily initialised on first search). So the method did nothing, leaving the old `.witness/index.orama` file on disk. Next search would load the old index.

The fix was twofold: if `vectorStore` is null, delete the file directly from disk. And after clearing, set `vectorStore` to null to ensure a fresh one is created next time.

**Chapter 4: Vector Search Returns Junk**

After re-indexing with the corrected context length, vector search still returned completely irrelevant results. Searching for "water" returned an empty document called "mica app" (content: just the word "gold"). Fulltext search worked fine, so the issue was specifically with vector similarity.

The root cause: **nomic-embed-text requires task prefixes**. Documents must be prefixed with `search_document: ` and queries with `search_query: `. Without these, both documents and queries embed into a generic space where similarity scores are meaningless. This is documented in nomic's model card but easy to miss.

We added `MODEL_TASK_PREFIXES`, `embedDocuments()`, and `embedQuery()` to OllamaProvider. The VectorStore was updated to use these instead of raw `embed()`.

**Chapter 5: Which Other Models Need Prefixes?**

This discovery raised an important question: do our other supported models also need prefixes? We researched each one systematically:

- **nomic-embed-text**: Both prefixes mandatory (search_document / search_query)
- **mxbai-embed-large**: Query prefix only ("Represent this sentence for searching relevant passages: ")
- **all-minilm**: No prefix needed
- **bge-m3**: No prefix needed
- **bge-large**: Optional query prefix (marginal improvement)
- **snowflake-arctic-embed**: Query prefix needed

We added mxbai-embed-large to the prefix map (the user's preferred model), with an empty document prefix and the full query prefix.

**Chapter 6: The Null Save Race Condition**

During indexing, the user hit "cannot read properties of null reading save". This was a race condition: `loadIndexCount()` (called when the settings tab opens) runs async and creates a VectorStore. If the user clicks "Build Index" before it completes, both paths create VectorStores, and one might go null before the other finishes.

Fix: the Build Index handler now captures a local `const vs = this.plugin.vectorStore` reference before the async loop. Even if `clearIndex()` or `loadIndexCount()` nullifies the plugin-level reference during indexing, the local reference remains valid.

**Chapter 7: Short Document Noise**

Even with prefixes fixed, short documents kept appearing in results. The "mica app" file (content: "gold") matched every query. This is a fundamental property of how embedding models work: short texts lack distinctive features, so their embeddings cluster near the centre of the vector space. Since cosine similarity measures the angle between vectors, these centroid-adjacent embeddings score moderately high against everything.

The solution: a configurable `minContentLength` setting (default 50 characters) that filters files by `file.stat.size` before indexing. This is a simple, effective improvement — the single most impactful setting for search quality besides choosing the right model.

### Technical Achievements

- **Dynamic model introspection**: No more guessing dimensions or context lengths from documentation. Query the model and cache the results.
- **Correct task prefix handling**: Embeddings now land in the right vector space for each model, producing meaningful similarity scores.
- **Race-condition-safe async UI**: Captured local references prevent null pointer errors during long-running operations.
- **Comprehensive model documentation**: Every supported embedding model researched and documented with its prefix requirements, context limits, and characteristics.

### Key Learnings

1. **`num_ctx` != context_length for BERT models**: The Modelfile parameter is for generative models. Embedding models have fixed architecture context windows. Always check the model's actual `context_length` from `/api/show` model_info.

2. **Task prefixes are not optional**: Some embedding models (nomic-embed-text, mxbai-embed-large) require specific prefixes to produce useful embeddings. Without them, documents and queries embed into a generic space where similarity is meaningless. Always check the model card.

3. **Short documents produce noise, not signal**: A file containing "gold" will match any query because it lacks distinctive features. Filtering by minimum content length is the cheapest and most effective quality improvement.

4. **Characters per token varies wildly**: English prose averages ~4 chars/token, but JSON, HTML, URLs, and special syntax can be as low as ~1.5. Use a conservative estimate (we use 2) for pre-truncation.

5. **Race conditions in async UI**: When a settings page loads data asynchronously and users can click buttons during loading, capture local references to mutable state. Don't rely on `this.plugin.vectorStore` remaining non-null across `await` boundaries.

6. **Web research first**: When hitting a bug with an external tool (Ollama, Orama, etc.), always check the API docs and other people's issues before guessing. The `truncate: true` parameter, the `/api/show` endpoint, and the task prefix requirements were all documented — we just needed to find them.

### Statistics

- 3 files changed, 81 insertions, 14 deletions (this session's commit)
- 26 files changed, ~4,700 insertions, ~1,200 deletions (full Ollama integration branch)
- 53 tests (52 passing, 1 pre-existing failure)
- 6 supported embedding models documented with prefix/context requirements
- 0 embedding failures after fixes (was 565)

### Files Changed

- `src/ollama-provider.ts` — Task prefixes, embedDocuments/embedQuery, resolveModelInfo
- `src/vector-store.ts` — Use embedDocuments/embedQuery instead of raw embed
- `src/main.ts` — minContentLength setting, race condition fixes, loadIndexCount, settings UI

### What's Next

- Markdown chunking — split long documents by headings before embedding for better retrieval on long files
- Background indexing — automatic incremental indexing with status bar indicator
- Re-ranking — optional Ollama-based re-ranking for higher precision
- Chaos triage — MCP tools for processing chaos items one at a time

### Reflections

This session was a masterclass in how many layers of subtlety hide behind "just call an embedding API". Context lengths aren't what they seem. Prefixes that look optional are mandatory. Short documents that seem harmless are the worst polluters. Each fix was simple once understood, but finding the root cause required peeling back assumptions layer by layer. The user's instinct to verify each model's documentation before committing to a prefix map was exactly right — different models have genuinely different APIs, and getting them wrong produces silently wrong results rather than obvious errors.

---

*End of log entry*

## 2026-02-08 - Markdown Chunking, Search Panel Polish & Unified Search Architecture

**Objective**: Implement markdown chunking for better retrieval on long documents, polish the search panel UI, and design the next-generation search architecture.

### What We Built

- **Markdown chunker** (`src/chunker.ts`) — Splits documents by H2 boundaries with H3 subdivision and fixed-size fallback for oversized chunks. Each chunk carries its heading path for context.
- **Schema v3 for VectorStore** — Added `sourcePath`, `headingPath`, `chunkIndex` fields. Documents are now multi-chunk with IDs like `filepath#0`, `filepath#1`.
- **Search panel redesign** — New result layout: title + score row, file path, section indicator with § symbol, snippet. Click-to-heading navigation via `openLinkText()`.
- **Frontmatter stripping** — Snippets now strip YAML frontmatter before showing the first 200 chars.
- **MCP response formatting** — `semantic_search` results now include heading path and snippet in the markdown response.
- **Unified search feature spec** (`docs/features/unified-search.md`) — Complete architecture for consolidating three search tools into two, switching BM25 → QPS, and adding tag/path filtering.
- **Chunker test suite** (`test/unit/chunker.test.ts`) — 19 tests covering H2/H3 splitting, frontmatter handling, edge cases.

### The Journey

The session started with implementing the chunker — a satisfying piece of pure logic that splits markdown by heading boundaries. The interesting design decisions were: should H3s subdivide H2 chunks? (Yes, for better retrieval granularity.) What about chunks with no headings? (Use the whole document as one chunk.) What about enormous chunks? (Fixed-size fallback at 5000 chars.)

With chunking working, the search panel needed a complete redesign. The old flat list of results didn't show which section of a document matched. The new layout shows the heading path with a § indicator, and clicking navigates directly to that heading in the document using Obsidian's `openLinkText()` with a heading anchor.

Then came the deeper architectural question: we now have three overlapping search tools (`search`, `semantic_search`, `find_files`). The brute-force `search` tool reads every file and regex-matches line by line — returning 77KB of unranked `file:line - text` noise for common queries. We explored whether Obsidian's built-in search API could replace it, but discovered there's no official headless search API — only low-level `prepareSimpleSearch`/`prepareFuzzySearch` string matchers and an undocumented internal plugin hack.

The breakthrough came from deep-diving into Orama's capabilities:
- **All schema fields are optional at insert time** — documents without embeddings are simply omitted from vector index but remain fully searchable via BM25
- **`enum[]` type** supports `containsAll`/`containsAny` operators — perfect for Obsidian tags
- **`where` filters** support `and`/`or`/`not` logical combinators
- **QPS (Quantum Proximity Scoring)** — a drop-in BM25 replacement that scores based on token proximity, making phrase-like queries ("carbon intensity") rank correctly

This led to the unified search architecture: two tools (`search` for content, `find` for file discovery), a `SearchEngine` abstraction interface, two-phase indexing (content first, embeddings second), and QPS for better text matching.

### Technical Achievements

1. **Heading-aware chunking** with path tracking (e.g., "## Overview > ### Principles")
2. **Multi-chunk deduplication** — search results show best chunk per file, not every chunk
3. **Click-to-heading navigation** in search panel via `openLinkText()` with heading anchors
4. **Complete feature spec** for unified search with MCP tool descriptions, schema design, and implementation plan
5. **67/68 tests passing** across unit and integration suites

### Key Learnings

1. **Orama schema fields are optional at insert time** — this is the key insight that enables indexing all files regardless of embedding success. Just omit the `embedding` field; the document stays in BM25/QPS index.

2. **QPS > BM25 for short queries** — Quantum Proximity Scoring tokenises into "quantums" and scores adjacency. For the 2-5 word queries typical in vault search, this dramatically improves relevance over BM25's bag-of-words approach.

3. **No headless search API in Obsidian** — `prepareFuzzySearch()` and `prepareSimpleSearch()` are the only official search functions. They're low-level string matchers, not the full search panel experience. The internal `global-search` plugin requires the UI panel to be open and `setTimeout` guessing for results.

4. **MCP tool descriptions are critical** — they're the only thing AI clients see when deciding how to use a tool. Must be comprehensive: list all parameters, example values, explain what each mode does, mention what requires Ollama vs what works without it.

5. **Orama `enum[]` with `containsAny`/`containsAll`** — the right primitive for tag filtering. Combined with `where` clause logical operators, this gives us the filtering power we need without building a custom query parser.

### Statistics

- 7 files modified, 5 new files created
- `src/chunker.ts`: 213 lines (new)
- `test/unit/chunker.test.ts`: 251 lines (new)
- `docs/features/unified-search.md`: 265 lines (new)
- 67/68 tests passing (1 pre-existing integration test failure)
- 19 new chunker tests + updated vector store tests

### What's Next

- **Unified search implementation** — Step 1: Engine abstraction, Step 2: Schema v5 + QPS, Step 3: Unified `search` tool, Step 4: `find` tool, Step 5: Update search panel, Step 6: Remove old tools
- Background indexing with status bar indicator
- Chaos triage MCP tools

### Reflections

This session was as much about architecture as implementation. The chunker was the coding deliverable, but the real value came from the deep exploration of search options — systematically comparing brute-force grep, Obsidian's API, and Orama's capabilities to arrive at a clear, well-reasoned architecture. The user's discovery of QPS was the final piece that made the all-in-Orama approach compelling. Sometimes the most productive sessions are the ones where you spend more time thinking than typing.

---

*End of log entry*
