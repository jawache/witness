# Witness Development Log

This log chronicles the development journey of Witness, an Obsidian plugin that implements the Model Context Protocol (MCP) to enable AI-assisted vault management.

---

## 2026-01-30 - Phase 1: MCP Server Implementation

**Objective**: Create an Obsidian plugin that acts as an MCP server running inside Obsidian, enabling Claude Desktop to interact with the vault.

### What We Built

Implemented a complete MCP server with 6 core tools:

1. **read_file** - Read any file from the vault
2. **write_file** - Create or modify files
3. **list_files** - Browse directory contents
4. **edit_file** - Find and replace text (surgical edits)
5. **search** - Full-text search across all markdown files
6. **execute_command** - Execute any Obsidian command by ID

### The Journey

**Morning: Architecture Decision**

Started with a critical architectural choice: Should the plugin BE the MCP server (Approach A) or should it be an external server connecting via REST API (Approach B)?

Decision: **Approach A** - Plugin runs the MCP server directly inside Obsidian. This means:
- Zero dependencies on other plugins
- Direct access to Obsidian's Vault API
- HTTP server running in Electron process
- More complex but more powerful

**Early Development: Initial Implementation**

First attempt was manual JSON-RPC message handling. Messy and error-prone. Quickly pivoted to using the official `@modelcontextprotocol/sdk` package for proper protocol compliance.

Initial tools: read_file, write_file, list_files working with manual testing via curl.

**The Great Session Management Mystery**

Hit a major blocker: "Server already initialized" error on every connection attempt from Claude Desktop. Spent considerable time investigating:

1. **Red Herring #1**: Node version issues
   - mcp-remote showed "File is not defined" errors
   - Tried forcing Node v24 via PATH environment
   - Turned out to be irrelevant - still works with Node v18

2. **The Real Problem**: Session Management
   - Was creating a new transport for EVERY HTTP request
   - Should create ONE transport per SESSION
   - Maintain a `Map<sessionId, transport>`
   - Only call `mcpServer.connect(transport)` once per session
   - Reuse transport for all subsequent requests in that session

**Breakthrough**: Found the pattern in SDK examples at `node_modules/@modelcontextprotocol/sdk/dist/esm/examples/server/simpleStreamableHttp.js`. The key insight: StreamableHTTP is stateful. Sessions span multiple HTTP requests.

**Second Major Issue**: SSE Stream 404 Errors

Tools were listing successfully, but then Claude Desktop couldn't establish the SSE (Server-Sent Events) stream for receiving notifications.

Problem: Only handling POST requests to `/mcp`, not GET requests.

Solution: StreamableHTTP uses dual endpoints:
- POST for sending JSON-RPC messages
- GET for SSE streams (receiving)

Also had to handle GET requests differently - no body to parse.

**Late Afternoon: Completing the Tool Set**

With the connection working, implemented the remaining three tools:

1. **edit_file**: Find/replace with proper regex escaping for literal matching
2. **search**: Full-text search with optional case sensitivity and path filtering
3. **execute_command**: Direct access to Obsidian's command system

All tools use Zod schemas for parameter validation, letting the SDK auto-generate JSON Schema.

### Technical Achievements

- **Proper Session Management**: Map-based transport tracking
- **SSE Support**: Bidirectional communication working
- **Type Safety**: Zod validation for all parameters
- **Error Handling**: Clear error messages with helpful suggestions
- **Zero External Dependencies**: No REST API plugins needed

### Documentation Created

- **README.md**: User-facing installation and usage guide
- **CLAUDE.md**: Technical implementation details for AI assistants
- **PHASE1-COMPLETE.md**: Comprehensive tool reference with examples
- **test-tools.sh**: Testing verification script
- **DEVLOG**: This file

### Key Learnings

1. **StreamableHTTP is stateful**: Don't create new transports per request
2. **Dual endpoints matter**: Handle both POST and GET for full functionality
3. **Read the SDK examples**: The answers are often in the source code
4. **Test methodically**: Health endpoint + logs + screenshots = debugging trinity
5. **Document as you go**: Future you will thank present you

### Statistics

- **4 commits** in main branch
- **452 lines** of TypeScript
- **6 tools** implemented
- **100%** Phase 1 objectives met

### Next Steps

Phase 2: Remote Access
- Cloudflare Tunnel integration
- WhatsApp/Telegram bot connection
- Mobile support
- Multi-user authentication
- Security hardening

### Reflections

The session management bug was frustrating but educational. It reinforced the importance of:
- Reading official examples thoroughly
- Not assuming the first error message is the real problem
- Systematic debugging rather than guessing
- Writing documentation that captures the "why" not just the "what"

Phase 1 is complete and working beautifully. The foundation is solid for Phase 2 expansion.

---

## 2026-01-31 - Integration Test Suite

**Objective**: Build automated testing infrastructure to verify MCP tools work correctly end-to-end.

### What We Built

A complete integration test suite using Vitest that tests all MCP tools against a running Obsidian instance.

**Test Infrastructure:**
- `test/vault/` - Minimal, stable test vault with known fixed content
- `test/integration/mcp-client.ts` - MCP protocol client for testing
- `test/integration/mcp.test.ts` - 17 integration tests covering all tools
- `test/vitest.config.ts` - Test configuration

**Vault Reorganization:**
- Renamed `test-vault/` â†’ `demo-vault/` for manual testing and development
- Created `test/vault/` for automated tests (port 3001)
- Clear separation: demo vault can change freely, test vault stays stable

**NPM Scripts:**
- `npm test` - Run integration tests
- `npm run test:watch` - Watch mode
- `npm run test:start-obsidian` - Launch Obsidian with test vault
- `npm run test:install-plugin` - Build and install plugin

### The Journey

**Design Decision: Integration vs Unit Tests**

Considered two approaches:
1. Mock-based unit tests - Fast but doesn't test real integration
2. Integration tests against running Obsidian - Slower but tests actual behavior

Chose integration tests because:
- Most plugin logic is tightly coupled to Obsidian's API
- Mocking the vault would be complex and fragile
- We need to verify files are actually created/modified
- MCP protocol nuances are hard to unit test

**Test Verification Strategy**

Made sure tests actually verify results, not just check for errors:
- `write_file`: Writes content, then reads it back to verify
- `edit_file`: Performs edit, then reads file to confirm change
- `read_file`: Checks returned content matches known file content
- `search`: Verifies correct files appear in results

**Initial Test Failures**

First run: 14/17 tests passed. The 3 failures were because MCP returns errors via `isError: true` flag rather than throwing exceptions. Updated tests to check `result.isError` instead of `expect(...).rejects.toThrow()`.

Second run: 17/17 tests pass.

### Technical Achievements

- **True End-to-End Testing**: Tests run against real Obsidian instance
- **All Tools Covered**: 17 tests for 8 MCP tools
- **Error Case Coverage**: Tests both success and error paths
- **Result Verification**: Tests read back data to verify operations worked
- **Clean Separation**: Test vault isolated from demo/development vault

### Test Coverage Summary

| Tool | Tests | Verification |
|------|-------|--------------|
| read_file | 2 | Content matches known file |
| write_file | 2 | Read back verifies content |
| edit_file | 2 | Read back verifies changes |
| list_files | 2 | Expected files present |
| search | 2 | Correct files in results |
| find_files | 2 | Pattern matching works |
| get_orientation | 1 | Returns orientation doc |
| execute_command | 2 | Success/error handling |

### Key Learnings

1. **MCP error handling**: Errors return `isError: true`, not exceptions
2. **TypeScript config**: Need to exclude test directory from main build
3. **Vitest config**: `sequence.concurrent: false` for sequential tests
4. **Port separation**: Test vault uses 3001 to avoid conflicts with demo

### Statistics

- **17 tests** all passing
- **166ms** test duration
- **2 vaults** (demo + test)
- **4 npm scripts** for testing workflow

### Next Steps

- Consider adding GitHub Actions CI
- Add more edge case tests as bugs are found
- Potential: Screenshot tests for UI verification

---

## 2026-01-31 - File-Based MCP Logging

**Objective**: Implement file-based logging so logs are accessible without Obsidian's Developer Console.

### What We Built

A logging system that writes MCP server logs to files in the plugin directory.

**MCPLogger Class:**

- Writes to both console AND file simultaneously
- Buffered writes (flushes every 1 second or 50 entries)
- Date-based log files: `mcp-YYYY-MM-DD.log`
- Log levels: INFO, ERROR, DEBUG, MCP
- ISO timestamps for all entries
- Graceful shutdown flushes remaining logs

**Log Location:**

```text
.obsidian/plugins/witness/logs/mcp-2026-01-31.log
```

**Log Format:**

```text
[2026-01-31T17:49:56.003Z] [INFO] Witness plugin loaded
[2026-01-31T17:50:07.214Z] [MCP] POST /mcp
[2026-01-31T17:50:07.242Z] [MCP] read_file called with path: "test.md"
```

### Benefits

1. **Debugging**: Claude Code can read logs directly to help debug issues
2. **Bug Reports**: Users can easily share logs when reporting problems
3. **No Console Required**: No need to open Developer Console to see what's happening
4. **History**: Date-based files provide historical record

### Testing

Added 2 new integration tests (now 19 total):

1. **should write logs to file** - Verifies log file exists and contains expected entries
2. **should log error cases** - Verifies failed operations are logged

### Implementation Details

Replaced all `console.log` and `console.error` calls with `this.logger.*` calls:

- `this.logger.info()` - General information
- `this.logger.error()` - Error conditions
- `this.logger.debug()` - Debug info
- `this.logger.mcp()` - MCP protocol-level logging

The logger buffers writes to avoid I/O overhead on every log call.

### Statistics

- **2 new tests** added
- **19 tests** total, all passing
- **~150 lines** of logging code
- **1 new class** (MCPLogger)

### Next Steps

- Implement `move_file` tool for moving/renaming files
- Consider log rotation for large vaults

---

## 2026-01-31 - Move/Rename File Tool

**Objective**: Implement `move_file` MCP tool to move or rename files within the vault.

### What We Built

A new `move_file` MCP tool that enables AI assistants to move or rename files within the vault using Obsidian's native `vault.rename()` API.

**Tool Implementation:**

- Takes `from` (source path) and `to` (destination path) parameters
- Uses Obsidian's `vault.rename()` for proper file system handling
- Automatically creates parent directories if needed
- Error handling for: source not found, destination already exists
- Marked as destructive (destructiveHint: true)
- Full logging integration

**Test Coverage:**

Added 4 new integration tests (23 total):
1. Should move/rename a file
2. Should move file to subfolder
3. Should return error for non-existent source
4. Should return error if destination exists

### Technical Details

```typescript
this.mcpServer.tool(
  'move_file',
  'Move or rename a file within the vault',
  {
    from: z.string().describe('Current path of the file'),
    to: z.string().describe('New path for the file'),
  },
  { destructiveHint: true },
  async ({ from, to }) => {
    const file = this.app.vault.getAbstractFileByPath(from);
    if (!file) throw new Error(`Source file not found: ${from}`);

    const existing = this.app.vault.getAbstractFileByPath(to);
    if (existing) throw new Error(`Destination already exists: ${to}`);

    // Create parent directories if needed
    const destDir = to.substring(0, to.lastIndexOf('/'));
    if (destDir) {
      const parentFolder = this.app.vault.getAbstractFileByPath(destDir);
      if (!parentFolder) {
        await this.app.vault.createFolder(destDir);
      }
    }

    await this.app.vault.rename(file, to);
    return { content: [{ type: 'text', text: `Moved ${from} to ${to}` }] };
  }
);
```

### Key Features

- **Preserves Metadata**: Unlike delete + create, rename preserves file creation date and other metadata
- **Parent Directory Creation**: Automatically creates destination directories if they don't exist
- **Conflict Prevention**: Fails safely if destination already exists
- **Full Logging**: Integrated with MCPLogger for debugging

### Statistics

- **4 new tests** added
- **23 tests** total, all passing
- **~50 lines** of new tool code
- **9 MCP tools** now available

### Next Steps

- Remote Access via Cloudflare Tunnel (Phase 2)

---

*End of log entry*
